---
title: "ETC5242 Assignment 1"
subtitle: "Group 42"
author: "Khuyen Nguyen: 33533113, Evan Ginting: 33477558, Rachitha Werake: 33519048"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
)
```

```{r loading-data}
library(broom)
library(gridExtra)
library(kableExtra)
library(MASS)
library(tidyverse)
grades <- read_csv("data/GradesData.csv")
```

# Task 1 - fit a distribution [30 marks]
### The lecturer wants to examine “genuine” (non-zero) attempts only. Check and modify the data (if necessary) to ensure that only genuine attempts are analysed. [1 mark]

```{r non-zero}
grades <- grades %>%
  filter(Total != 0)
```

### Traditionally Normal distributions have been used to model grade distributions. Plot your data and explain whether you think that this is good idea in this instance. [3 marks]

```{r norm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
grades %>%
  ggplot(aes(x = Total, y = after_stat(density))) +
  geom_histogram(colour = "blue", fill = "blue", alpha = 0.2, bins = 30) +
  geom_density(colour = "blue", fill = "blue", alpha = 0.2) +
  ggtitle("Distribution of Total Scores (n = 193)") +
  xlab("Total Score") +
  ylab("Density") +
  theme_bw()
```
- As can be seen from the plot, the distribution of total score is left-skewed. Most of the score are recorded within the higher range of the scale (>= 0.6), with a long tail towards the lower range (< 0.6).
- A normal distribution, being symmetric, may not be able to capture this skewness perfectly. Hence, it is probably not the best idea to use a normal distribution to fit the sample scores for this case. 


### An alternative is the beta distribution. Explain why this may be a valid alternative in this case. [2 marks]
The beta distribution is also a viable option. To use it, we'll need to determine the parameter estimates $\alpha$ and $\beta$. Observing that the distribution shows a left-skew, the beta distribution may be well-suited for this situation. Additionally, since the test scores range from 0 to 1, the beta distribution's domain aligns with the data range.


### Use Maximum Likelihood to fit both a Normal and Beta distribution to the grades. Use a Bootstrap QQplot to assess the fit of each. Which distribution do you recommend? Be sure to briefly explain your reasoning. [8 marks]

**Normal Distribution Fit**
```{r}
x <- grades$Total
n <- nrow(grades) 
df <- tibble(id = 1:n, x = x)

normal_fit <- fitdistr(x, "normal")
normal_fit %>% tidy()
```

**QQplot Normal Distribution**
```{r qqnorm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params <- normal_fit$estimate 

p <- ggplot(df, aes(sample = x)) + 
  stat_qq(distribution = qnorm, dparams = params) + 
  stat_qq_line(distribution = qnorm, dparams = params, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Normal Distribution") +
  xlab("Theoretical") + ylab("Total Score")
p 
```

**Assessing the fitness of normal distribution using Bootstrap QQplot**
```{r qqnorm_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
set.seed(10) 

MLE.x <- normal_fit$estimate 

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA,2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(df$x, size = n, replace = TRUE) 
  df <- df %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "normal")$estimate 
  params_boot <- MLE.x_boot[i,] 
  p <- p + stat_qq(aes(sample = temp), distribution = qnorm, dparams = params_boot, colour = "grey", alpha = 0.2)
} 

p <- p + stat_qq(aes(sample = x), distribution = qnorm, dparams = params) +
  ggtitle("QQ plot with B=500 Bootstrap Replicates (Normal Distribution)")

p
```

**Beta Distribution Fit**
```{r, warning = FALSE}
set.seed(10)

#alpha.true <- 0.6 
#beta.true <- 0.4 

#x_beta <- rbeta(n, shape1 = alpha.true, shape2 = beta.true)
dt <- tibble(id = 1:n, x = x)

betadist_fit <- fitdistr(x, "beta", start = list(shape1 = 1, shape2 = 1)) 
betadist_fit
```

```{r}
betadist_fit %>% tidy() ##CHECK
```

**QQplot Beta Distribution**
```{r qqbeta_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params_betadist <- betadist_fit$estimate 

p_betadist <- ggplot(dt, aes(sample = x)) + 
  stat_qq(distribution = qbeta, dparams = params_betadist) + 
  stat_qq_line(distribution = qbeta, dparams = params_betadist, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Beta Distribution") +
  xlab("Theoretical") + ylab("Sample")
p_betadist
```
**Assessing the fitness of beta distribution using Bootstrap QQplot**
```{r qqbeta_dist_boot, out.width = "100%", fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning = FALSE}
set.seed(10)

MLE.x <- betadist_fit$estimate  

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA, 2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(dt$x, size = n, replace = TRUE) 
  dt <- dt %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate 
  params_boot <- MLE.x_boot[i,] 
  p_betadist <- p_betadist + stat_qq(aes(sample = temp), distribution = qbeta, dparams = params_boot, colour = "grey", alpha = 0.2)
} 

p_betadist <- p_betadist + stat_qq(aes(sample = x), distribution = qbeta, dparams = params_betadist) +
  ggtitle("QQ plot with B=500 Bootstrap Replicates (Beta Distribution)")

p_betadist
```

**Recommendation**
Based on the Bootstrap QQ plots, we would recommend using the Beta distribution. You can observe that the grey confidence intervals on the Beta distribution have fewer points deviating from the line compared to the Normal distribution. In the Normal distribution, points deviate at both the beginning and end of the line, whereas for the Beta distribution, the fit is only slightly off at the beginning.


### The lecturer is interested in trying the Beta distribution. Use your MLE’s to report the mean and the median of the grade distribution (recall that the mean is a function of the shape and rate parameters). Be sure to interpret these values. [4 marks]

```{r}
alpha <- as.numeric(betadist_fit$estimate[1])
beta <- as.numeric(betadist_fit$estimate[2])
mean <- alpha/(alpha + beta)
median <- qbeta(0.5, alpha, beta)
```

The mean of the Beta distribution is given by the formula: $\text{E}(X) = \frac{\alpha}{\alpha+\beta}$. 

Given our shape and rate parameters were 5.95 and 2.63 respectively, our mean is: $E[X] = \frac{5.95}{5.95+2.63} = 0.693$.

The median of the Beta distribution is `r round(median, 3)`, confirming the slight left skew we mentioned earlier.


### Plot and interpret a 99% parametric bootstrap of the mean of the beta distribution (HINT: set warning=FALSE in your code chunk). Did the average quiz mark match the lecturer’s goal? [4 marks]
**Defining the bootplot function**
```{r bootplot_f}
# Define bootplot.f functions at the start
bootplot.f<- function(stat.boot, bins=50, a=.01){
  
  df <- tibble(stat = stat.boot)
  CI <- round(quantile(stat.boot, c(0.025, 0.975)),2)
  
  p <- df %>% ggplot(aes(x=stat, y=after_stat(density))) +  
    geom_histogram(bins=bins, colour="grey", fill="grey", alpha=0.2) + 
    geom_density(fill="green", colour="green", alpha=0.2) +
    geom_vline(xintercept = CI, colour = "black", linetype=5) +
    theme_bw()
  
  p
}
```

**Plotting the mean of the beta distribution**
```{r mean_beta_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning=FALSE}
set.seed(10) 

B <- 500
MLE.x_boot <- matrix(nrow=B, ncol=2) 
MLE.x_mean <- matrix(nrow = B, ncol = 1)
for(i in 1:B){ 
  temp <- sample(dt$x, size=n, replace=TRUE) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate
  MLE.x_mean[i] <- as.numeric(MLE.x_boot[i,1]) / (as.numeric(MLE.x_boot[i,1]) + as.numeric(MLE.x_boot[1,2]))
}
boot.LCI.mean <- quantile(MLE.x_mean[], c(0.005, 0.995))
boot.LCI.mean

p_MLEboot.mean <- bootplot.f(MLE.x_mean[], bins = 100) +
  ggtitle("Sampling distribution for MLE of mean of beta distribution of grades") +
  xlab("MLE of mean") +
  theme_bw()

p_MLEboot.mean
```

### Using the MLE’s, what is the estimated proportion of students within 15% of the average? According to the lecturer’s benchmark, what proportion would have failed? How many would get HD’s? [4 marks]
```{r}
lower_bound <- mean - 0.15 * mean
upper_bound <- mean + 0.15 * mean

within_15_prct <- pbeta(upper_bound, alpha, beta) - pbeta(lower_bound, alpha, beta)

failed <- pbeta(0.60, alpha, beta)
hd <- 1 - pbeta(0.80, alpha, beta)
```

- From the beta distribution, there are `r round(within_15_prct*100, 2)`% of students that are within 15% of the average.
- Assuming that "Pass" is above 60%, then the proportion of student that failed the quiz is `r round(failed*100,2)`%, which is `r floor(failed*193)` students out of 193.
- Assuming that "HD" is above 80%, then the proportion of students that got HD is `r round(hd*100,2)`%, which is `r floor(hd*193)` students out of 193.


### Overall, do you think that the quiz achieved the lecturer’s aims? [4 marks]
Overall, we would say that the quiz achieved the lecturer's aims. The average mark fell around 70%, which is within the range that was expected for the lecturer. Additionally, 48.65% of students scored within 15% of the MLE mean of the grades, which suggests that the quiz was fair and that students were able to demonstrate their understanding of the material. However, the benchmark of 60% could be considered quite high, as 25.83% of the class failed. This suggests that the quiz may have been too difficult for some students, and that the lecturer may want to reconsider the benchmark in the future.


## Task 2 - Are Postgrad students better? [30 marks]

### Create a new variable “Result” which contains the values “Pass” or “Fail” depending on the value of the variable Total, and add it to your dataframe. (Hint: If you have the MASS package loaded, the dplyr command select will not work. Add dplyr::before any select command in your code.) [4 marks]

```{r}
grades <- grades %>%
  mutate(Result = dplyr::case_when(
    Total < 0.6 ~ "Fail",
    Total >= 0.6 ~ "Pass"
  ))
```

### Report a table with the relevant proportions and discuss the result. [10 marks]

```{r}
grades1 <- grades %>%
  group_by(Result, Cohort) %>%
  tally() %>%
  ungroup()

grades2 <- grades1 %>% 
  pivot_wider(names_from = Result, values_from = n) 

grades3 <- grades2 %>% 
  mutate(Total = Fail + Pass) %>% 
  mutate(Prop = round(Pass/Total, digits=3)) %>%
  select(Cohort, Pass, Fail, Total, Prop) 

grades4 <- grades3 %>% 
  arrange(desc(row_number())) 

grades4 %>% 
  kable() %>% 
  kable_styling()
```
There are more students enrolled in the undergraduate cohort (145 compared to 48), with a higher number of students passing and failing than in the postgraduate cohort (102 compared to 41). However, there is a higher proportion of students who passed in the postgraduate cohort compared to the undergraduate cohort, with 82% passing compared to 68%.

### Conduct a permutation test with 5000 replications. Plot the sampling distribution of your test. [4 marks]

```{r}
n <- nrow(grades)
R <- 5000
Rxobs <- array(dim = R)
set.seed(10)
Rgrades <- grades

for (r in 1:R) {
  Rgrades <- Rgrades %>% mutate(Cohort = sample(Rgrades$Cohort, n, replace=FALSE))
  
  Rgrades3 <- Rgrades %>% 
    group_by(Cohort, Result) %>% 
    tally() %>%
    ungroup() %>% 
    pivot_wider(names_from = Result, values_from = n) %>%
    mutate(Total = Fail + Pass) %>% 
    mutate(Prop = round(Pass/Total, digits=3))
 
  Rxobs[r] <- Rgrades3$Prop[grades3$Cohort=='PG'] - Rgrades3$Prop[grades3$Cohort=='UG']
  
}

xobs <- 0.151

pval <- sum(Rxobs >= xobs)/R
options(digits = 4)
```

```{r}
Rxobs_tbl <- as_tibble(Rxobs) %>% mutate(r=1:R)

Rxobs_tbl %>%
  ggplot(aes(value)) +
  geom_histogram(colour="blue", fill="blue", alpha=0.5, bins=R)  +
  xlab(expression(xobs^"[r]")) + 
  ggtitle(expression(paste("Approximate sampling distribution of ", hat(p)[PG] - hat(p)[UG], " under ", H[0]))) +
  geom_vline(xintercept=xobs, color="red")
```

### What is the result of this test? (Be sure to properly define the null and alternative hypothesis and discuss the result of the test). [8 marks]

We want to test whether the sample supports the hypothesis that the pass and fail rates are the same for both the UG and PG cohorts. To do that, we need to determine whether the difference in proportions is equal to 0 or greater than 0 and whether it is statistically significant.

Null Hypothesis ($H_0$): There is no difference in pass and fail rates between the UG and PG cohorts.
Alternative Hypothesis ($H_1$): There is evidence to suggest that there is a difference between the pass and fail rates of the UG and PG cohorts.

Using a 95% confidence interval ($\alpha$ = 0.05), which is equal to 1 - $\alpha$ and $\alpha$/2:
The $p$-value of the test is 0.0292 which is less than 0.05, given a confidence level of 95%.

Therefore, there is significant evidence to reject the null hypothesis in favour of the alternative hypothesis: there is a difference between the pass and fail rates of the UG and PG cohorts

### The lecturer may be confused as to why such a large difference in proportions does not have a p-value of almost 0. Explain why this may occur. [4 marks]

A large difference in proportions may not necessarily result in a $p$-value close to 0 due to factors such as the sample size and the observed difference, as well as the alpha level.

Our results indicate that it's unlikely we would observe a difference of this magnitude by chance. However, it doesn't claim this as an absolute truth; it's solely based on our observed difference and the sample size presented to us.

A larger sample size may yield to smaller p-values when there is a substantial difference between proportions exists. This is because a larger sample provides more statistical power to detect differences accurately.

The alpha level chosen will also affect the p-value. In this case, using an alpha level of 95% means there was a 5% chance that we are incorrect when we rejected the null hypothesis.

A lower alpha level implies a stricter criterion for significance, resulting in smaller p-values if the observed difference is substantial. Conversely, a higher alpha level increases the likelihood of a Type I error, where you incorrectly reject the null hypothesis.

## Task 3 - Bayesian Analysis [33 marks]

### Suggest (and justify) an appropriate prior distribution for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

An appropriate prior distribution for the proportion of postgraduate students who "passed" and one for the proportion of undergraduate students who "passed" would be a beta distribution. 

A beta distribution is appropriate because: 
  - Beta distributions are conjugate to the binomial distribution, which can model our binary outcomes of pass and fail.
  - The beta distribution is also flexible using shape parameters alpha and beta to represent a more accurate belief on our prior beliefs or available data. For example, when we modelled our data before it was slightly skewed.
  - It also ranges between 0 and 1, which is accurate for our analysis.

### State the posterior distributions for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

The posterior distribution for the proportion of postgraduate students who "passed" and the proportion of undergraduate students who "passed" remains in the form of a beta distribution. 

The formula $\text{Posterior} \propto \text{Likelihood} \times \text{Prior}$ means: The posterior is proportional to the likelihood multiplied by the prior. When updating our prior belief with the likelihood (which follows a binomial distribution), we obtain a new beta distribution for the posterior. The parameters of this posterior beta distribution are updated based on the data and prior information. 

The beta distribution is parameterised by two shape parameters, alpha and beta, and after updating, these parameters will have new values that reflect our updated beliefs and knowledge about the proportions of students who "passed".

### Obtain 95% credible intervals for the proportion postgraduate students who “passed” and for the proportion of undergraduate students who “passed”. Comment on how these two intervals compare to each other. [4 marks]

There is a 95% probability that the true proportion of postgraduate students who passed falls within the range of x to x.

There is a 95% probability that the true proportion of undergraduate students who passed falls within the range of x to x.

### Obtain and interpret the estimator that minimises the posterior expected squared error loss for the proportion of students who “passed” for a given cohort. Is this in a form that linearly combines a purely data-based estimator and some prior quantity? If so, quantify the contribution of the databased estimator by deriving the credibility factor. Using the data, calculate the estimate and credibility factor for both cohorts of students. [8 marks]

### State the estimator that minimises the posterior expected absolute error loss for the proportion of students who “passed” for a given cohort. Using the data, calculate the estimate for both cohorts of students. [4 marks]

### For each cohort of students, visualise the posterior distribution the proportion of students who “passed”. Discuss any interesting features. [3 marks]

### The lecturer wishes to do this again next semester. What priors do you suggest that she use? Explain your reasoning. [2 marks]

### Simulate the posterior distribution of the difference in the proportion of postgraduate students who “passed” and the proportion of undergraduate students who “passed”. [4 marks]

### Give the lecturer an indication of the probability that the difference in the grades of the 2 cohorts is within 0.15. Be sure to provide a visualisation of the posterior to support your indication. [4 marks]