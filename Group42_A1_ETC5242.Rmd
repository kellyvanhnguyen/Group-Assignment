---
title: "ETC5242 Assignment 1"
subtitle: "Group 42"
author: "Khuyen Nguyen: kngu0086@student.monash.edu, Evan Ginting: 33477558, Rachitha Werake: 33519048"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
)
```

```{r loading-data}
library(broom)
library(gridExtra)
library(kableExtra)
library(MASS)
library(tidyverse)
grades <- read_csv("data/GradesData.csv")
```

# Task 1 - fit a distribution [30 marks]
### The lecturer wants to examine “genuine” (non-zero) attempts only. Check and modify the data (if necessary) to ensure that only genuine attempts are analysed. [1 mark]

```{r non-zero}
grades <- grades %>%
  filter(Total != 0)
```

### Traditionally Normal distributions have been used to model grade distributions. Plot your data and explain whether you think that this is good idea in this instance. [3 marks]

```{r norm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
grades %>%
  ggplot(aes(x = Total, y = after_stat(density))) +
  geom_histogram(colour = "blue", fill = "blue", alpha = 0.2, bins = 30) +
  geom_density(colour = "blue", fill = "blue", alpha = 0.2) +
  ggtitle("Distribution of Total Score (n = 193)") +
  xlab("Total Score") +
  theme_bw()
```
- As can be seen from the plot, the distribution of total score is left-skewed. Most of the score are recorded within the higher range of the scale (>= 0.6), with a long tail towards the lower range (< 0.6).
- A normal distribution, being symmetric, may not be able to capture this skewness perfectly. Hence, it is probably not a best idea to use normal distribution to fit sample score for this case. 


### An alternative is the beta distribution. Explain why this may be a valid alternative in this case. [2 marks]
The beta distribution is also a viable option. To use it, we'll need to determine the parameter estimates $\alpha$ and $\beta$. Observing that the distribution shows a left-skewed, the beta distribution may be well-suited for this situation. Additionally, since the test scores range from 0 to 1, the beta distribution's domain aligns with the data range.


### Use Maximum Likelihood to fit both a Normal and Beta distribution to the grades. Use a Bootstrap QQplot to assess the fit of each. Which distribution do you recommend? Be sure to briefly explain your reasoning. [8 marks]

#### Normal Distribution

**Normal Distribution Fit**
```{r}
x <- grades$Total
n <- nrow(grades) 
df <- tibble(id = 1:n, x = x)

normal_fit <- fitdistr(x, "normal")
normal_fit %>% tidy()
```

**QQplot Normal Distribution**
```{r qqnorm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params <- normal_fit$estimate 

p <- ggplot(df, aes(sample = x)) + 
  stat_qq(distribution = qnorm, dparams = params) + 
  stat_qq_line(distribution = qnorm, dparams = params, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Normal Distribution") +
  xlab("Theoretical") + ylab("Total Score")
p 
```

**Assessing the fitness of normal distribution using Bootstrap QQplot**
```{r qqnorm_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
set.seed(10) 

MLE.x <- normal_fit$estimate 

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA,2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(df$x, size = n, replace = TRUE) 
  df <- df %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "normal")$estimate 
  params_boot <- MLE.x_boot[i,] 
  p <- p + stat_qq(aes(sample = temp), distribution = qnorm, dparams = params_boot, colour = "grey", alpha = 0.2)
} 

p <- p + stat_qq(aes(sample = x), distribution = qnorm, dparams = params) +
  ggtitle("QQ plot with B=500 Bootstrap replicates (Normal Distribution)")

p
```

#### Beta Distribution

**Beta Distribution Fit**
```{r, warning = FALSE}
set.seed(10)

#alpha.true <- 0.6 
#beta.true <- 0.4 

#x_beta <- rbeta(n, shape1 = alpha.true, shape2 = beta.true)
dt <- tibble(id = 1:n, x = x)

betadist_fit <- fitdistr(x, "beta", start = list(shape1 = 1, shape2 = 1)) 
betadist_fit
```

```{r}
betadist_fit %>% tidy() ##CHECK
```

**QQplot Beta Distribution**
```{r qqbeta_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params_betadist <- betadist_fit$estimate 

p_betadist <- ggplot(dt, aes(sample = x)) + 
  stat_qq(distribution = qbeta, dparams = params_betadist) + 
  stat_qq_line(distribution = qbeta, dparams = params_betadist, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Beta Distribution") +
  xlab("Theoretical") + ylab("Sample")
p_betadist
```
**Assessing the fitness of beta distribution using Bootstrap QQplot**
```{r qqbeta_dist_boot, out.width = "100%", fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning = FALSE}
set.seed(10)

MLE.x <- betadist_fit$estimate  

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA, 2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(dt$x, size = n, replace = TRUE) 
  dt <- dt %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate 
  params_boot <- MLE.x_boot[i,] 
  p_betadist <- p_betadist + stat_qq(aes(sample = temp), distribution = qbeta, dparams = params_boot, colour = "grey", alpha = 0.2)
} 

p_betadist <- p_betadist + stat_qq(aes(sample = x), distribution = qbeta, dparams = params_betadist) +
  ggtitle("QQ plot with B=500 Bootstrap replicates (Beta Distribution)")

p_betadist
```

#### Recommendation
Based on the Bootstrap QQ plots, We would recommend using the Beta distribution. You can observe that the grey confidence intervals on the Beta distribution have fewer points deviating from the line compared to the Normal distribution. In the Normal distribution, points deviate at both the beginning and end of the line, whereas for the Beta distribution, the fit is only slightly off at the beginning.


### The lecturer is interested in trying the Beta distribution. Use your MLE’s to report the mean and the median of the grade distribution (recall that the mean is a function of the shape and rate parameters). Be sure to interpret these values. [4 marks]

```{r}
alpha <- as.numeric(betadist_fit$estimate[1])
beta <- as.numeric(betadist_fit$estimate[2])
mean <- alpha/(alpha + beta)
median <- qbeta(0.5, alpha, beta)
```

The mean of the Beta distribution is given by the formula: $\text{E}(X) = \frac{\alpha}{\alpha+\beta}$. 

Given our shape and rate parameters were 5.95 and 2.63 respectively, our mean is: $E[X] = \frac{5.95}{5.95+2.63} = 0.693$.

The median of the Beta distribution is `r round(median, 3)`, confirming the slight left skew we mentioned earlier.


### Plot and interpret a 99% parametric bootstrap of the mean of the beta distribution (HINT: set warning=FALSE in your code chunk). Did the average quiz mark match the lecturer’s goal? [4 marks]
**Defining the bootplot function**
```{r bootplot_f}
# Define bootplot.f functions at the start
bootplot.f<- function(stat.boot, bins=50, a=.01){
  
  df <- tibble(stat = stat.boot)
  CI <- round(quantile(stat.boot, c(0.025, 0.975)),2)
  
  p <- df %>% ggplot(aes(x=stat, y=after_stat(density))) +  
    geom_histogram(bins=bins, colour="grey", fill="grey", alpha=0.2) + 
    geom_density(fill="green", colour="green", alpha=0.2) +
    geom_vline(xintercept = CI, colour = "black", linetype=5) +
    theme_bw()
  
  p
}
```

**Plotting the mean of the beta distribution**
```{r mean_beta_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning=FALSE}
set.seed(10) 

B <- 500
MLE.x_boot <- matrix(nrow=B, ncol=2) 
MLE.x_mean <- matrix(nrow = B, ncol = 1)
for(i in 1:B){ 
  temp <- sample(dt$x, size=n, replace=TRUE) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate
  MLE.x_mean[i] <- as.numeric(MLE.x_boot[i,1]) / (as.numeric(MLE.x_boot[i,1]) + as.numeric(MLE.x_boot[1,2]))
}
boot.LCI.mean <- quantile(MLE.x_mean[], c(0.005, 0.995))
boot.LCI.mean

p_MLEboot.mean <- bootplot.f(MLE.x_mean[], bins = 100) +
  ggtitle("Sampling distribution for MLE of mean of beta distribution of grades") +
  xlab("MLE of mean") +
  theme_bw()

p_MLEboot.mean
```

### Using the MLE’s, what is the estimated proportion of students within 15% of the average? According to the lecturer’s benchmark, what proportion would have failed? How many would get HD’s? [4 marks]
```{r}
lower_bound <- mean - 0.15 * mean
upper_bound <- mean + 0.15 * mean

within_15_prct <- pbeta(upper_bound, alpha, beta) - pbeta(lower_bound, alpha, beta)

failed <- pbeta(0.60, alpha, beta)
hd <- 1 - pbeta(0.80, alpha, beta)
```

- From the beta distribution, there are `r round(within_15_prct*100, 2)`% student that is within 15% of the average.
- Assuming that "Pass" is above 60%, then the proportion of student that failed the quiz is `r round(failed*100,2)`%, which is `r floor(failed*193)` students out of 193.
- Assuming that "HD" is above 80%, then the proportion of student that got HD is `r round(hd*100,2)`%, which is `r floor(hd*193)` students out of 193.


### Overall, do you think that the quiz achieved the lecturer’s aims? [4 marks]
Overall, We would say that the quiz achieved the lecturer's aims. The average mark fell around 70%, which is within the range that was expected for the lecturer. Additionally, 48.65% of students scored within 15% of the MLE mean of the grades, which suggests that the quiz was fair and that students were able to demonstrate their understanding of the material. However, the benchmark of 60% could be considered quite high, as 25.83% of the class failed. This suggests that the quiz may have been too difficult for some students, and that the lecturer may want to reconsider the benchmark in the future.


## Task 2 - Are Postgrad students better? [30 marks]

### Create a new variable “Result” which contains the values “Pass” or “Fail” depending on the value of the variable Total, and add it to your dataframe. (Hint: If you have the MASS package loaded, the dplyr command select will not work. Add dplyr::before any select command in your code.) [4 marks]

```{r}
grades <- grades %>%
  mutate(Result = dplyr::case_when(
    Total < 0.6 ~ "Fail",
    Total >= 0.6 ~ "Pass"
  ))
```

### Report a table with the relevant proportions and discuss the result. [10 marks]

```{r}
grades1 <- grades %>%
  group_by(Result, Cohort) %>%
  tally() %>%
  ungroup()

grades2 <- grades1 %>% 
  pivot_wider(names_from = Result, values_from = n) 

grades3 <- grades2 %>% 
  mutate(Total = Fail + Pass) %>% 
  mutate(Prop = round(Pass/Total, digits=3)) %>%
  select(Cohort, Pass, Fail, Total, Prop) 

grades4 <- grades3 %>% 
  arrange(desc(row_number())) 

grades4 %>% 
  kable() %>% 
  kable_styling()
```
There are more students enrolled in the undergraduate cohort, with a higher number of students passing and failing than in the postgraduate cohort. However, there is a higher proportion of students who passed in the postgraduate cohort compared to the undergraduate cohort, with 82% passing compared to 68%.

### Conduct a permutation test with 5000 replications. Plot the sampling distribution of your test. [4 marks]

```{r}
n <- nrow(grades)

T3grades <- grades %>%
  select(Cohort, Result)

xobs <-  grades4$Prop[grades4$Cohort=='PG'] - grades4$Prop[grades4$Cohort=='UG']

R <- 5000

Rxobs <- array(dim = R)

set.seed(10)

RGrades <- T3grades

for (r in 1:R) {

  RGrades <- RGrades %>% mutate(Cohort = sample(RGrades$Cohort, n, replace=FALSE))
  
  RGDSS3 <- RGrades %>% 
    group_by(Cohort, Result) %>% 
    tally() %>%
    ungroup() %>% 
    pivot_wider(names_from = Result, values_from = n) %>%
    mutate(total = Fail + Pass) %>% 
    mutate(prop = round(Pass/total, digits=3))
 
  Rxobs[r] <- RGDSS3$prop[grades3$Cohort =='PG'] - RGDSS3$prop[grades3$Cohort =='UG']
}

pval <- sum(Rxobs >= xobs)/R
options(digits = 4)

Rxobs_tbl <- as_tibble(Rxobs) %>% mutate(r=1:R)

Rxobs_tbl %>%
  ggplot(aes(value)) +
  geom_histogram(colour="blue", fill="blue", alpha=0.5, bins=R)  +
  xlab(expression(xobs^"[r]")) + 
  ggtitle(expression(paste("Approximate sampling distribution of ", hat(p)[M] - hat(p)[F], " under ", H[0]))) +
  geom_vline(xintercept=xobs, color="red")

```
###What is the result of this test? (Be sure to properly define the null and alternative hypothesis and discuss the result of the test). [8 marks]

The Null Hypothesis (H0): There is no difference between the grade rates of the undergraduate students and the postgraduate students.

The Alternative Hypothesis (HA): The is evidence present that shows that there is a difference between the grade rates of the undergraduate and the postgraduate students. 

The P-value is equal to : `r pval`

The plot represents a sampling distribution of proportion differences generated under the assumption that H0 is true (i.e. that postgraduate students perform better than undergraduate students). The red line shows the proportion difference that we observed from our sample.

Based on the plot and the p-value, we can say with 95% confidence that there is evidence to reject the null hypothesis (H0), thus, it can be concluded that there is no difference between the grade rates of the postgraduate and the undergraduate students.

Based on the plot and the p-value, we can say with 99% confidence that there is not enough evidence to reject the null hypothesis (H0), thus, it can be concluded that there is no difference between the grade rates of the postgraduate and the undergraduate students.

###The lecturer may be confused as to why such a large difference in proportions does not have a p-value of almost 0. Explain why this may occur. [4 marks]
P-value's are based and influenced on various factors such as the chosen alpha (e.g. a 95% confidence level will mean that there will be a 5% chance of an error occurring), the sample size and the observed difference, as such a large difference within the proportions may not always lead to a p-value close to 0. 



## Task 3 - Bayesian Analysis [33 marks]
```{r}
beta_binomial <-function(n, x, alpha = 1, beta = 1) {
  atil <- alpha+x
  btil <- beta+n-x
  out <-list(alpha_tilde = atil, beta_tilde = btil)
  return(out)
  }
```
###Suggest (and justify) an appropriate prior distribution for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

An appropriate prior distribution for the proportion of postgraduate students who "passed" and one for the proportion of undergraduate students who "passed" would be a beta distribution. 

A beta distribution is appropriate because: 
  - Beta distributions are conjugate to the binomial distribution, which can model our binary outcomes of pass and fail.
  - The beta distribution is also flexible using shape parameters alpha and beta to represent a more accurate belief on our prior beliefs or available data. For example, when we modelled our data before it was slightly skewed.
  - It also ranges between 0 and 1, which is accurate for our analysis.

###State the posterior distributions for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

The posterior distribution for the proportion of postgraduate students who "passed" and the proportion of undergraduate students who "passed" remains in the form of a beta distribution. 

The formula $\text{Posterior} \propto \text{Likelihood} \times \text{Prior}$ means: The posterior is proportional to the likelihood multiplied by the prior. When updating our prior belief with the likelihood (which follows a binomial distribution), we obtain a new beta distribution for the posterior. The parameters of this posterior beta distribution are updated based on the data and prior information. 

###Obtain 95% credible intervals for the proportion postgraduate students who “passed” and for the proportion of undergraduate students who “passed”. Comment on how these two intervals compare to each other. [4 marks]
```{r}
LUstar <- qbeta(c(0.025,0.975), alpha, beta)
```
Undergraduate Students:
```{r}
UN_n <- 145
LU_UG <- UN_n * LUstar
LU_UG
```
Postgraduate Students:
```{r}
PG_n <- 48
LU_PG <- PG_n * LUstar
LU_PG
```
Approximately 54 to 135 students from the undergraduate cohort have passed. Compared to Postgraduate, where approximately 18 to 45 students have passed.

###Obtain and interpret the estimator that minimises the posterior expected squared error loss for the proportion of students who “passed” for a given cohort. Is this in a form that linearly combines a purely data-based estimator and some prior quantity? If so, quantify the contribution of the database estimator by deriving the credibility factor. Using the data, calculate the estimate and credibility factor for both cohorts of students. [8 marks]

**Undergraduate Students Posterior and Credibility Factor:**
```{r}
xUG <- 102
UG_Posterior <- beta_binomial(n = UN_n, x = xUG, alpha = alpha , beta = beta)
UG_Posterior
```
**Undergraduate Estimator:**
```{r}
UG_Estimator <- UG_Posterior$alpha_tilde / UG_Posterior$beta_tilde
UG_Estimator
```
**Postgraduate Students Posterior and Credibility Factor:**
```{r}
xPG <- 41
PG_Posterior <- beta_binomial(n - PG_n, x = xPG, alpha = alpha, beta = beta)
PG_Posterior
```
**Postgraduate Estimator:**
```{r}
PG_Estimator <- PG_Posterior$alpha_tilde / PG_Posterior$beta_tilde
PG_Estimator
```

###State the estimator that minimises the posterior expected absolute error loss for the proportion of students who “passed” for a given cohort. Using the data, calculate the estimate for both cohorts of students. [4 marks]
**Undergraduate Students:**
```{r}
E_UG_AE <- qbeta(0.5, UG_Posterior$alpha_tilde, UG_Posterior$beta_tilde)
E_UG_AE
```
**Postgraduate Students:**
```{r}
E_PG_AE <- qbeta(0.5, PG_Posterior$alpha_tilde, PG_Posterior$beta_tilde)
E_PG_AE
```
###For each cohort of students, visualise the posterior distribution the proportion of students who “passed”. Discuss any interesting features. [3 marks]

```{r}
#PG STUDENTS
R <- 10000 
set.seed(2023)

# Simulate from the posterior of PG 
samplePG <- rbeta(R, PG_Posterior$alpha_tilde, PG_Posterior$beta_tilde)
sampleUG <- rbeta(R, UG_Posterior$alpha_tilde, PG_Posterior$beta_tilde)


ds_PG <- tibble(sample = samplePG)
p1 <- ds_PG %>%
  ggplot(aes(x = samplePG, y = ..density..)) +
  geom_histogram(colour = "green", fill = "blue", alpha = 0.4, bins = 100) +
  geom_density(colour = "blue", fill = "grey", alpha = 0.4) +
  ggtitle("Posterior pdf of Postgraduate Students") +
  xlab("Sample")

ds_UG <- tibble(sample = sampleUG)
p2 <- ds_UG <- ds_UG %>%
  ggplot(aes(x = sampleUG, y = ..density..)) +
  geom_histogram(colour = "green", fill = "blue", alpha = 0.4, bins = 100) +
  geom_density(colour = "blue", fill = "grey", alpha = 0.4) +
  ggtitle("Posterior pdf of Undergraduate Students") +
  xlab("Sample")

grid.arrange(p1,p2, nrow = 2)
```
Both distributions show a relatively normal distribution. However, the mean of the distributions for both the postgraduate students and undergraduate students differ from each other, with postgraduate's having a mean of approximately 0.3 and undergraduate's having a mean of approximately 0.50.

###The lecturer wishes to do this again next semester. What priors do you suggest that she use? Explain your reasoning. [2 marks]
When choosing a new prior for the next semester, it is recomended that the lecturer takes into consideration her previous prior and the their respective liklihoods. 
