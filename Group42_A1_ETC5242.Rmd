---
title: "ETC5242 Assignment 1"
subtitle: "Group 42"
author: "Khuyen Nguyen: 33533113, Evan Ginting: 33477558, Rachitha Werake: 33519048"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
)
```

```{r loading-data, echo=FALSE}
library(broom)
library(gridExtra)
library(kableExtra)
library(MASS)
library(tidyverse)
grades <- read_csv("data/GradesData.csv")
```

# Task 1 - fit a distribution [30 marks]
### The lecturer wants to examine “genuine” (non-zero) attempts only. Check and modify the data (if necessary) to ensure that only genuine attempts are analysed. [1 mark]

```{r non-zero}
grades <- grades %>%
  filter(Total != 0)
```

### Traditionally Normal distributions have been used to model grade distributions. Plot your data and explain whether you think that this is good idea in this instance. [3 marks]

```{r norm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
grades %>%
  ggplot(aes(x = Total, y = after_stat(density))) +
  geom_histogram(colour = "blue", fill = "blue", alpha = 0.2, bins = 30) +
  geom_density(colour = "blue", fill = "blue", alpha = 0.2) +
  ggtitle("Distribution of Total Scores (n = 193)") +
  xlab("Total Score") +
  theme_bw()
```
- As can be seen from the plot, the distribution of total scores is left-skewed. Most of the scores are recorded within the higher range of the scale (>= 0.6), with a long tail towards the lower range (< 0.6).
- A normal distribution, being symmetric, may not be able to capture this skewness perfectly. Hence, it is probably not the best idea to use a normal distribution to fit sample scores for this case. 


### An alternative is the beta distribution. Explain why this may be a valid alternative in this case. [2 marks]
The beta distribution is also a viable option. To use it, we'll need to determine the parameter estimates $\alpha$ and $\beta$. Observing that the distribution shows a left-skew, the beta distribution may be well-suited for this situation. Additionally, since the test scores range from 0 to 1, the beta distribution's domain aligns with the data range.


### Use Maximum Likelihood to fit both a Normal and Beta distribution to the grades. Use a Bootstrap QQplot to assess the fit of each. Which distribution do you recommend? Be sure to briefly explain your reasoning. [8 marks]

**Normal Distribution Fit**
```{r}
x <- grades$Total
n <- nrow(grades) 
df <- tibble(id = 1:n, x = x)

normal_fit <- fitdistr(x, "normal")
normal_fit %>% tidy()
```

**QQplot Normal Distribution**
```{r qqnorm_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params <- normal_fit$estimate 

p <- ggplot(df, aes(sample = x)) + 
  stat_qq(distribution = qnorm, dparams = params) + 
  stat_qq_line(distribution = qnorm, dparams = params, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Normal Distribution") +
  xlab("Theoretical") + ylab("Total Score")
```

**Assessing the fitness of normal distribution using Bootstrap QQplot**
```{r qqnorm_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
set.seed(10) 

MLE.x <- normal_fit$estimate 

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA,2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(df$x, size = n, replace = TRUE) 
  df <- df %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "normal")$estimate 
  params_boot <- MLE.x_boot[i,] 
  p <- p + stat_qq(aes(sample = temp), 
                   distribution = qnorm, 
                   dparams = params_boot, 
                   colour = "grey", alpha = 0.2)
} 

p <- p + stat_qq(aes(sample = x), distribution = qnorm, dparams = params) +
  ggtitle("QQ plot with B=500 Bootstrap replicates (Normal Distribution)")

p
```

**Beta Distribution Fit**
```{r, warning = FALSE}
set.seed(10)

#alpha.true <- 0.6 
#beta.true <- 0.4 

#x_beta <- rbeta(n, shape1 = alpha.true, shape2 = beta.true)
dt <- tibble(id = 1:n, x = x)

betadist_fit <- fitdistr(x, "beta", start = list(shape1 = 1, shape2 = 1)) 
betadist_fit %>% tidy()
```

**QQplot Beta Distribution**
```{r qqbeta_dist, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE}
params_betadist <- betadist_fit$estimate 

p_betadist <- ggplot(dt, aes(sample = x)) + 
  stat_qq(distribution = qbeta, dparams = params_betadist) + 
  stat_qq_line(distribution = qbeta, dparams = params_betadist, color = "black") +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  ggtitle("QQ plot of Total Scores according to a Beta Distribution") +
  xlab("Theoretical") + ylab("Sample")
```

**Assessing the fitness of beta distribution using Bootstrap QQplot**
```{r qqbeta_dist_boot, out.width = "100%", fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning = FALSE}
set.seed(10)

MLE.x <- betadist_fit$estimate  

boot.seq <- seq(1,n,1)/n-1/(2*n) 

B <- 500 

MLE.x_boot <- matrix(rep(NA, 2*B), nrow = B, ncol = 2) 
for(i in 1:B){ 
  temp <- sample(dt$x, size = n, replace = TRUE) 
  dt <- dt %>% mutate(temp = temp) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate 
  params_boot <- MLE.x_boot[i,] 
  p_betadist <- p_betadist + stat_qq(aes(sample = temp), 
                                     distribution = qbeta, 
                                     dparams = params_boot, 
                                     colour = "grey", 
                                     alpha = 0.2)
} 

p_betadist <- p_betadist + stat_qq(aes(sample = x), 
                                   distribution = qbeta, 
                                   dparams = params_betadist) +
  ggtitle("QQ plot with B=500 Bootstrap replicates (Beta Distribution)")

p_betadist
```

#### Recommendation
Based on the Bootstrap QQ plots, we would recommend using the Beta distribution. You can observe that the grey confidence intervals on the Beta distribution have fewer points deviating from the line compared to the Normal distribution. In the Normal distribution, points deviate at both the beginning and end of the line, whereas for the Beta distribution, the fit is only slightly off at the beginning.


### The lecturer is interested in trying the Beta distribution. Use your MLE’s to report the mean and the median of the grade distribution (recall that the mean is a function of the shape and rate parameters). Be sure to interpret these values. [4 marks]

```{r}
alpha <- as.numeric(betadist_fit$estimate[1])
beta <- as.numeric(betadist_fit$estimate[2])
mean <- alpha/(alpha + beta)
median <- qbeta(0.5, alpha, beta)
```

The mean of the Beta distribution is given by the formula: $\text{E}(X) = \frac{\alpha}{\alpha+\beta}$. 

Given our shape and rate parameters were 5.95 and 2.63 respectively, our mean is: $E[X] = \frac{5.95}{5.95+2.63} = 0.693$.

The median of the Beta distribution is `r round(median, 3)`, confirming the slight left skew we mentioned earlier.


### Plot and interpret a 99% parametric bootstrap of the mean of the beta distribution (HINT: set warning=FALSE in your code chunk). Did the average quiz mark match the lecturer’s goal? [4 marks]
**Defining the bootplot function**
```{r bootplot_f}
# Define bootplot.f functions at the start
bootplot.f<- function(stat.boot, bins=50, a=.01){
  
  df <- tibble(stat = stat.boot)
  CI <- round(quantile(stat.boot, c(0.025, 0.975)),2)
  
  p <- df %>% ggplot(aes(x=stat, y=after_stat(density))) +  
    geom_histogram(bins=bins, colour="grey", fill="grey", alpha=0.2) + 
    geom_density(fill="green", colour="green", alpha=0.2) +
    geom_vline(xintercept = CI, colour = "black", linetype=5) +
    theme_bw()
  
  p
}
```

**Plotting the mean of the beta distribution**
```{r mean_beta_dist_boot, out.width = "100%" , fig.align = "center", fig.width = 6, fig.height = 4, eval = TRUE, echo = TRUE, warning=FALSE}
set.seed(10) 

B <- 500
MLE.x_boot <- matrix(nrow=B, ncol=2) 
MLE.x_mean <- matrix(nrow = B, ncol = 1)
for(i in 1:B){ 
  temp <- sample(dt$x, size=n, replace=TRUE) 
  MLE.x_boot[i,] <- fitdistr(temp, "beta", start = list(shape1 = 1, shape2 = 1))$estimate
  MLE.x_mean[i] <- as.numeric(MLE.x_boot[i,1]) / (as.numeric(MLE.x_boot[i,1]) + 
                                                    as.numeric(MLE.x_boot[1,2]))
}
boot.LCI.mean <- quantile(MLE.x_mean[], c(0.005, 0.995))
boot.LCI.mean

p_MLEboot.mean <- bootplot.f(MLE.x_mean[], bins = 100) +
  ggtitle("Sampling distribution for MLE of mean of beta distribution of grades") +
  xlab("MLE of mean") +
  theme_bw()

p_MLEboot.mean
```

### Using the MLE’s, what is the estimated proportion of students within 15% of the average? According to the lecturer’s benchmark, what proportion would have failed? How many would get HD’s? [4 marks]
```{r}
lower_bound <- mean - 0.15 * mean
upper_bound <- mean + 0.15 * mean

within_15_prct <- pbeta(upper_bound, alpha, beta) - pbeta(lower_bound, alpha, beta)

failed <- pbeta(0.60, alpha, beta)
hd <- 1 - pbeta(0.80, alpha, beta)
```

- From the beta distribution, there are `r round(within_15_prct*100, 2)`% student that is within 15% of the average.
- Assuming that "Pass" is above 60%, then the proportion of student that failed the quiz is `r round(failed*100,2)`%, which is `r floor(failed*193)` students out of 193.
- Assuming that "HD" is above 80%, then the proportion of student that got HD is `r round(hd*100,2)`%, which is `r floor(hd*193)` students out of 193.


### Overall, do you think that the quiz achieved the lecturer’s aims? [4 marks]
Overall, We would say that the quiz achieved the lecturer's aims. The average mark fell around 70%, which is within the range that was expected for the lecturer. Additionally, 48.65% of students scored within 15% of the MLE mean of the grades, which suggests that the quiz was fair and that students were able to demonstrate their understanding of the material. However, the benchmark of 60% could be considered quite high, as 25.83% of the class failed. This suggests that the quiz may have been too difficult for some students, and that the lecturer may want to reconsider the benchmark in the future.


## Task 2 - Are Postgrad students better? [30 marks]

### Create a new variable “Result” which contains the values “Pass” or “Fail” depending on the value of the variable Total, and add it to your dataframe. (Hint: If you have the MASS package loaded, the dplyr command select will not work. Add dplyr::before any select command in your code.) [4 marks]

```{r}
grades <- grades %>%
  mutate(Result = dplyr::case_when(
    Total < 0.6 ~ "Fail",
    Total >= 0.6 ~ "Pass"
  ))
```

### Report a table with the relevant proportions and discuss the result. [10 marks]
```{r}
grades_s1 <- grades %>%
              group_by(Cohort, Result) %>%
              tally() %>%
              ungroup()

grades_s2 <- grades_s1 %>%
              pivot_wider(names_from = Result, values_from = n)

grades_s3 <- grades_s2 %>%
              mutate(Total = Fail + Pass) %>%
              mutate(Prop = round(Pass/Total, digits = 3)) %>%
              select(Cohort, Pass, Fail, Total, Prop)

grades_s4 <- grades_s3 %>%
              arrange(desc(row_number()))

grades_s4 %>% 
  kable(caption = "Proportion of Students who Passed or Failed") %>% 
  kable_styling()
```
As can be seen from the table above, there are more Under-Graduate (UG) students who enroll in the unit with the total of 145 students, compare to Post-Graduate (PG) students with the total of 48 students. However, when discussing about the "Pass" rate, PG students score higher rate with 0.854, while UG students score 0.703, this is a difference of 0.151. In overall, this means, out of 48 PG students, 41 students are passed the quiz, while 7 students are failed, on the other hand, out of 145 UG students, 102 students are passed the unit, while 43 students are failed.


### Conduct a permutation test with 5000 replications. Plot the sampling distribution of your test. [4 marks]
**Permutation Test**
```{r}
xobs <- grades_s4$Prop[grades_s4$Cohort == "PG"] - grades_s4$Prop[grades_s4$Cohort == "UG"]

n <- nrow(grades) 
R <- 5000 
Rxobs <- array(dim = R) 

set.seed(10) 

Rgrades <- grades 
for (r in 1:R) { 
  Rgrades <- Rgrades %>% 
    mutate(Cohort = sample(Rgrades$Cohort, n, replace = FALSE))
  Rgrades3 <- Rgrades %>% 
    group_by(Cohort, Result) %>% 
    tally() %>% 
    ungroup() %>% 
    pivot_wider(names_from = Result, values_from = n) %>% 
    mutate(Total = Fail + Pass) %>% 
    mutate(Prop = round(Pass/Total, digits = 3))
  Rxobs[r] <- Rgrades3$Prop[grades_s3$Cohort == "PG"] - Rgrades3$Prop[grades_s3$Cohort == "UG"]
}

pval <- sum(Rxobs >= xobs)/R
options(digits = 4)
```

**Plotting the Sampling Distribution**
```{r}
Rxobs_tbl <- as_tibble(Rxobs) %>% mutate(r=1:R)

Rxobs_tbl %>%
  ggplot(aes(value)) +
  geom_histogram(colour="blue", fill="blue", alpha=0.5, bins=R)  +
  xlab(expression(xobs^"[r]")) + 
  ggtitle(expression(paste("Approximate sampling distribution of PG against UG"))) +
  geom_vline(xintercept=xobs, color="red") +
  theme_bw()
```


### What is the result of this test? (Be sure to properly define the null and alternative hypothesis and discuss the result of the test).

We want to test whether the sample supports the hypothesis that the pass and fail rates are the same for both the UG and PG cohorts. To do that, we need to determine whether the difference in proportions is equal to 0 or not and whether it is statistically significant.

$$H_0: p_{PG}-p_{UG} = 0 \quad \mbox{vs.} \quad H_1: p_{PG}-p_{UG} \neq 0,$$
where ${p}_{PG}$ and ${p}_{UG}$ denote the population proportions of postgraduate and undergraduate students passing the quiz, respectively.

Null Hypothesis ($H_0$): There is no difference in pass and fail rates between the UG and PG cohorts.

Alternative Hypothesis ($H_1$): There is evidence to suggest that there is a difference between the pass and fail rates of the UG and PG cohorts.

Using a 95% confidence interval (which corresponds to a significance level of $\alpha = 0.05$), we conducted a hypothesis test.

The p-value of the test is 0.0292, which is less than the chosen significance level of 0.05. Therefore, we have significant evidence to reject the null hypothesis in favor of the alternative hypothesis, indicating that there is a difference between the pass and fail rates of the UG and PG cohorts.

To further support this conclusion, we can visually observe from the plot that the observed difference (represented by the red line) is far from 0. This suggests that it is unlikely to have arisen from a distribution that assumes no difference between PG and UG students.

### The lecturer may be confused as to why such a large difference in proportions does not have a p-value of almost 0. Explain why this may occur. [4 marks]
The reason why this happens may significantly because of the sample size. As we know, the PG sample size is 48 while UG sample size is 145, they almost have hundred of different sample size. Since the p-value is influenced by the size of the sample, if we have small sample size, we have less data points to estimate population parameters accurately, which lead to a larger standard error (a measure of the variability of the sample). In turn, providing a lower test statistic. A lower test statistic contributes to a smaller p-value. 


## Task 3 - Bayesian Analysis [33 marks]

The lecturer is curious about using Bayesian analysis to compare the proportion of postgraduate students who “passed” with undergraduate students who “passed”. The lecturer has no real opinion as to what the distribution of marks for each cohort would be.

```{r}
# Set-up the beta binomial function
beta_binomial <- function(n, x, alpha = 1, beta = 1) { 
  atil <- alpha + x 
  btil <- beta + n - x 
  z <- n / (alpha + beta + n) 
  out <- list(alpha_tilde = atil, beta_tilde = btil, credibility_factor = z) 
  return(out)
}

beta_meanvar <- function(alpha = 1, beta = 1) { 
  mean <- alpha / (alpha + beta) 
  var <- mean * beta / ((alpha + beta) * (alpha + beta + 1)) 
  out <- list(mean = mean, var = var) 
  return(out)
}
```


### Suggest (and justify) an appropriate prior distribution for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

An appropriate prior distribution for the proportion of postgraduate students who "passed" and one for the proportion of undergraduate students who "passed" would be a beta distribution. 

A beta distribution is appropriate because: 

  - Beta distributions are conjugate to the binomial distribution, which can model our binary outcomes of pass and fail.
  - The beta distribution is also flexible using shape parameters alpha and beta to represent a more accurate belief on our prior beliefs or available data. For example, when we modelled our data before it was slightly skewed.
  - It also ranges between 0 and 1, which is accurate for our analysis.

### State the posterior distributions for the proportion of postgraduate students who “passed” and one for the proportion of undergraduate students who “passed”. [2 marks]

The posterior distribution for the proportion of postgraduate students who "passed" and the proportion of undergraduate students who "passed" remains in the form of a beta distribution. 

The formula $\text{Posterior} \propto \text{Likelihood} \times \text{Prior}$ means: The posterior is proportional to the likelihood multiplied by the prior. When updating our prior belief with the likelihood (which follows a binomial distribution), we obtain a new beta distribution for the posterior. The parameters of this posterior beta distribution are updated based on the data and prior information. 

The beta distribution is parameterised by two shape parameters, alpha and beta, and after updating, these parameters will have new values that reflect our updated beliefs and knowledge about the proportions of students who "passed".

```{r}
nPG <- 48 #student count
nUG <- 145 #student count

# PG Students
alphaPG <- 1
betaPG <- 1
xPG <- 41 #"Pass" count of PG students 
Posterior_PG <- beta_binomial(n = nPG, x = xPG, alpha = alphaPG, beta = betaPG)

# UG Students
alphaUG <- 1
betaUG <- 1
xUG <- 102 #"Pass" count
Posterior_UG <- beta_binomial(n = nUG, x = xUG, alpha = alphaUG, beta = betaUG)
```


### Obtain 95% credible intervals for the proportion postgraduate students who “passed” and for the proportion of undergraduate students who “passed”. Comment on how these two intervals compare to each other. [4 marks]
```{r}
# PG Credible Interval
nPG <- 48 #student count
LUstar_PG <- qbeta(c(0.025, 0.975), Posterior_PG$alpha_tilde, Posterior_PG$beta_tilde)
LU_PG <- nPG * LUstar_PG
LU_PG


# UG Credible Interval
nUG <- 145 #student count
LUstar_UG <- qbeta(c(0.025, 0.975), Posterior_UG$alpha_tilde, Posterior_UG$beta_tilde)
LU_UG <- nUG * LUstar_UG
LU_UG
```

There is a 95% probability that the true number of postgraduate students who passed falls within the range of 34.92 to 44.49.

There is a 95% probability that the true number of undergraduate students who passed falls within the range of 90.55 to 111.90.

### Obtain and interpret the estimator that minimises the posterior expected squared error loss for the proportion of students who “passed” for a given cohort. Is this in a form that linearly combines a purely data-based estimator and some prior quantity? If so, quantify the contribution of the databased estimator by deriving the credibility factor. Using the data, calculate the estimate and credibility factor for both cohorts of students. [8 marks]
```{r}
# PG STUDENTS
## Credibility Factor of PG Students
### This had been calculated using beta binomial function to show Posterior Dist. of PG Students
Posterior_PG$credibility_factor

## Estimator that minimises the posterior expected squared loss for PG (Posterior Mean)
E_PG <- Posterior_PG$alpha_tilde / (Posterior_PG$alpha_tilde + Posterior_PG$beta_tilde)
E_PG


# UG STUDENTS
## Credibility Factor of UG Students
### This had been calculated using beta binomial function to show Posterior Dist. of UG Students 
Posterior_UG$credibility_factor

## Estimator that minimises the posterior expected squared loss for PG (Posterior Mean)
E_UG <- Posterior_UG$alpha_tilde / (Posterior_UG$alpha_tilde + Posterior_UG$beta_tilde)
E_UG
```


### State the estimator that minimises the posterior expected absolute error loss for the proportion of students who “passed” for a given cohort. Using the data, calculate the estimate for both cohorts of students. [4 marks]
```{r}
# PG STUDENTS
## Estimator that minimises the posterior expected absolute loss for PG (Posterior Median)
E_PG_AE <- qbeta(0.5, Posterior_PG$alpha_tilde, Posterior_PG$beta_tilde)
E_PG_AE  

# UG STUDENTS
## Estimator that minimises the posterior expected absolute loss for PG (Posterior Median)
E_UG_AE <- qbeta(0.5, Posterior_UG$alpha_tilde, Posterior_UG$beta_tilde) 
E_UG_AE
```


### For each cohort of students, visualise the posterior distribution the proportion of students who “passed”. Discuss any interesting features. [3 marks]
```{r}
#PG STUDENTS
R <- 10000 
set.seed(2023)

# Simulate from the posterior of PG 
samplePG <- rbeta(R, Posterior_PG$alpha_tilde, Posterior_PG$beta_tilde)

# Visualise the Posterior Dist. of PG
ds_PG <- tibble(sample = samplePG) 
p1 <- ds_PG %>% 
      ggplot(aes(x = samplePG, y = ..density..)) +
        geom_histogram(colour = "blue", fill = "blue", alpha = 0.4, bins = 100) +
        geom_density( colour = "blue", fill = "gray", alpha = 0.4) + 
        #geom_vline(xintercept = c(0.01, -0.01), colour = "red") + 
        ggtitle("Simulated posterior pdf of PG Students") + 
        xlab("Sample") +
        theme_bw()


#UG STUDENTS
# Simulate from the posterior of UG 
sampleUG <- rbeta(R, Posterior_UG$alpha_tilde, Posterior_UG$beta_tilde)

# Visualise the Posterior Dist. of UG
ds_UG <- tibble(sample = sampleUG) 
p2 <- ds_UG %>% 
      ggplot(aes(x = sampleUG, y = ..density..)) +
        geom_histogram(colour = "blue", fill = "blue", alpha = 0.4, bins = 100) +
        geom_density( colour = "blue", fill = "gray", alpha = 0.4) + 
        #geom_vline(xintercept = c(0.01, -0.01), colour = "red") + 
        ggtitle("Simulated posterior pdf of UG Students") + 
        xlab("Sample") +
        theme_bw()

grid.arrange(p1,p2, nrow = 2)
```



### The lecturer wishes to do this again next semester. What priors do you suggest that she use? Explain your reasoning. [2 marks]

For the next semester, we recommend using the posterior distribution from the previous semester as the prior, specifically a beta distribution. This approach adheres to Bayesian principles, incorporating the latest data.

Additionally, utilising a uniform distribution as the prior will ensure an unbiased perspective each year.

### Simulate the posterior distribution of the difference in the proportion of postgraduate students who “passed” and the proportion of undergraduate students who “passed”. [4 marks]
```{r}
# Difference
sample_diff <- samplePG - sampleUG
Posterior_PG_meanvar <- beta_meanvar(Posterior_PG$alpha_tilde, Posterior_PG$beta_tilde) 
Posterior_UG_meanvar <- beta_meanvar(Posterior_UG$alpha_tilde, Posterior_UG$beta_tilde) 
delta_mean <- Posterior_PG_meanvar$mean - Posterior_UG_meanvar$mean 
delta_var <- Posterior_PG_meanvar$var + Posterior_UG_meanvar$var
c(delta_mean, delta_var)
```



### Give the lecturer an indication of the probability that the difference in the grades of the 2 cohorts is within 0.15. Be sure to provide a visualisation of the posterior to support your indication. [4 marks]
```{r}
# Visualise the difference
ds_diff <- tibble(delta = sample_diff)
ds_diff %>% 
      ggplot(aes(x = delta, y = ..density..)) +
        geom_histogram(colour = "blue", fill = "blue", alpha = 0.4, bins = 100) +
        geom_density( colour = "blue", fill = "gray", alpha = 0.4) + 
        geom_vline(xintercept = 0.15, colour = "red") + 
        ggtitle(expression(paste("Simulated posterior pdf of ", Delta))) + 
        xlab(expression(Delta)) +
        theme_bw()
```




